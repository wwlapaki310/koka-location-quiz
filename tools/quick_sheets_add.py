#!/usr/bin/env python3
"""
ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆç°¡æ˜“è¿½åŠ ãƒ„ãƒ¼ãƒ«
JSON/CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ãƒ‡ãƒ¼ã‚¿ã‚’ç°¡å˜è¿½åŠ 

ä½¿ç”¨æ–¹æ³•:
python quick_sheets_add.py --file data.json
python quick_sheets_add.py --file data.csv --format csv
"""

import gspread
from google.oauth2.service_account import Credentials
import json
import csv
import argparse
import logging
from datetime import datetime
from typing import List, Dict, Any
import time

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class QuickSheetsAdder:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆè¿½åŠ ãƒ„ãƒ¼ãƒ«"""
    
    # å›ºå®šã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆID
    SPREADSHEET_ID = "1ukF5ZhpwJkN21wHLTaTS13BYTk5puKPisdQ1fGR5BwE"
    SHEET_NAME = "å­¦æ ¡ãƒã‚¹ã‚¿ãƒ¼"
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼å®šç¾©
    HEADERS = [
        "ID", "å­¦æ ¡å", "éƒ½é“åºœçœŒ", "å¸‚åŒºç”ºæ‘", "ä½æ‰€",
        "ç·¯åº¦", "çµŒåº¦", "æ ¡æ­Œã‚¿ã‚¤ãƒˆãƒ«", "æ ¡æ­Œå…¨æ–‡", "ãƒã‚¹ã‚¯æ¸ˆã¿æ­Œè©",
        "ä½œæ›²è€…", "ä½œè©è€…", "é›£æ˜“åº¦", "å“è³ªãƒ¬ãƒ™ãƒ«", "å“è³ªã‚¹ã‚³ã‚¢",
        "ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹", "åé›†æ—¥", "ãƒ’ãƒ³ãƒˆ_éƒ½é“åºœçœŒ", "ãƒ’ãƒ³ãƒˆ_åœ°åŸŸ", "ãƒ’ãƒ³ãƒˆ_ç‰¹å¾´",
        "å­¦æ ¡ç¨®åˆ¥", "è¨­ç½®è€…", "è¨­ç«‹å¹´", "åˆ¶å®šå¹´", "å‚™è€ƒ", "è‘—ä½œæ¨©çŠ¶æ³"
    ]
    
    def __init__(self, credentials_file: str = "credentials.json"):
        """åˆæœŸåŒ–"""
        self.credentials_file = credentials_file
        self.gc = None
        self.sheet = None
        self.authenticate()
        
    def authenticate(self):
        """Googleèªè¨¼"""
        try:
            scopes = [
                'https://www.googleapis.com/auth/spreadsheets',
                'https://www.googleapis.com/auth/drive'
            ]
            
            creds = Credentials.from_service_account_file(
                self.credentials_file, scopes=scopes
            )
            
            self.gc = gspread.authorize(creds)
            logger.info("âœ… Googleèªè¨¼æˆåŠŸ")
            
            # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ¥ç¶š
            self.spreadsheet = self.gc.open_by_key(self.SPREADSHEET_ID)
            self.sheet = self.spreadsheet.worksheet(self.SHEET_NAME)
            logger.info(f"âœ… ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ¥ç¶š: {self.spreadsheet.title}")
            
        except FileNotFoundError:
            logger.error(f"âŒ èªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.credentials_file}")
            raise
        except Exception as e:
            logger.error(f"âŒ èªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def ensure_headers(self):
        """ãƒ˜ãƒƒãƒ€ãƒ¼ç¢ºèªãƒ»è¨­å®š"""
        try:
            existing_headers = self.sheet.row_values(1)
            
            if not existing_headers or len(existing_headers) < len(self.HEADERS):
                logger.info("ğŸ“‹ ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¨­å®šä¸­...")
                self.sheet.update('A1', [self.HEADERS])
                
                # ãƒ˜ãƒƒãƒ€ãƒ¼ã®æ›¸å¼è¨­å®š
                self.sheet.format('A1:Z1', {
                    'backgroundColor': {'red': 0.2, 'green': 0.6, 'blue': 1.0},
                    'textFormat': {
                        'bold': True,
                        'foregroundColor': {'red': 1, 'green': 1, 'blue': 1}
                    }
                })
                logger.info("âœ… ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®šå®Œäº†")
            else:
                logger.info("âœ… ãƒ˜ãƒƒãƒ€ãƒ¼ç¢ºèªæ¸ˆã¿")
                
        except Exception as e:
            logger.warning(f"âš ï¸ ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®šã§å•é¡Œç™ºç”Ÿ: {e}")
    
    def get_next_id(self) -> int:
        """æ¬¡ã®IDã‚’å–å¾—"""
        try:
            all_values = self.sheet.get_all_values()
            if len(all_values) <= 1:  # ãƒ˜ãƒƒãƒ€ãƒ¼ã®ã¿
                return 1
            
            # IDã‚«ãƒ©ãƒ ã‹ã‚‰æœ€å¤§å€¤ã‚’å–å¾—
            max_id = 0
            for row in all_values[1:]:  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
                if row and row[0].strip():  # IDãŒã‚ã‚‹å ´åˆ
                    try:
                        current_id = int(row[0])
                        max_id = max(max_id, current_id)
                    except ValueError:
                        continue
            
            return max_id + 1
            
        except Exception as e:
            logger.warning(f"âš ï¸ IDå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return 1
    
    def load_json_data(self, file_path: str) -> List[Dict]:
        """JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if isinstance(data, list):
                return data
            elif isinstance(data, dict):
                return [data]
            else:
                logger.error(f"âŒ ä¸æ­£ãªJSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: {type(data)}")
                return []
                
        except Exception as e:
            logger.error(f"âŒ JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def load_csv_data(self, file_path: str) -> List[Dict]:
        """CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                return list(reader)
                
        except Exception as e:
            logger.error(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def convert_to_row(self, data: Dict, school_id: int) -> List[str]:
        """ãƒ‡ãƒ¼ã‚¿ã‚’è¡Œå½¢å¼ã«å¤‰æ›"""
        return [
            str(school_id),
            data.get('school_name', ''),
            data.get('prefecture', ''),
            data.get('city', ''),
            data.get('address', ''),
            str(data.get('latitude', '')),
            str(data.get('longitude', '')),
            data.get('song_title', 'æ ¡æ­Œ'),
            data.get('full_lyrics', ''),
            data.get('masked_lyrics', ''),
            data.get('composer', ''),
            data.get('lyricist', ''),
            data.get('difficulty', ''),
            data.get('quality_level', ''),
            str(data.get('quality_score', '')),
            data.get('data_source', ''),
            data.get('collection_date', datetime.now().strftime('%Y-%m-%d')),
            data.get('hints', {}).get('prefecture', ''),
            data.get('hints', {}).get('region', ''),
            data.get('hints', {}).get('landmark', ''),
            data.get('school_type', ''),
            data.get('establishment_type', ''),
            str(data.get('established_year', '')),
            str(data.get('composed_year', '')),
            data.get('notes', ''),
            data.get('copyright_status', '')
        ]
    
    def add_data_batch(self, data_list: List[Dict], batch_size: int = 10) -> bool:
        """ãƒ‡ãƒ¼ã‚¿ä¸€æ‹¬è¿½åŠ """
        if not data_list:
            logger.warning("âš ï¸ è¿½åŠ ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return False
        
        logger.info(f"ğŸ“¤ {len(data_list)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ä¸­...")
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼ç¢ºèª
        self.ensure_headers()
        
        # æ¬¡ã®IDã‚’å–å¾—
        next_id = self.get_next_id()
        logger.info(f"ğŸ“Š é–‹å§‹ID: {next_id}")
        
        success_count = 0
        total_batches = (len(data_list) + batch_size - 1) // batch_size
        
        for batch_num in range(total_batches):
            start_idx = batch_num * batch_size
            end_idx = min(start_idx + batch_size, len(data_list))
            batch_data = data_list[start_idx:end_idx]
            
            try:
                # ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã‚’è¡Œå½¢å¼ã«å¤‰æ›
                rows = []
                for i, item in enumerate(batch_data):
                    school_id = next_id + start_idx + i
                    row = self.convert_to_row(item, school_id)
                    rows.append(row)
                
                # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«è¿½åŠ 
                self.sheet.append_rows(rows)
                success_count += len(rows)
                
                logger.info(f"âœ… ãƒãƒƒãƒ {batch_num + 1}/{total_batches}: {len(rows)}ä»¶è¿½åŠ å®Œäº†")
                
                # APIåˆ¶é™å¯¾ç­–ï¼ˆå°‘ã—å¾…æ©Ÿï¼‰
                if batch_num < total_batches - 1:  # æœ€å¾Œã®ãƒãƒƒãƒã§ãªã„å ´åˆ
                    time.sleep(2)
                
            except Exception as e:
                logger.error(f"âŒ ãƒãƒƒãƒ {batch_num + 1} è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ç¶™ç¶š
                continue
        
        logger.info(f"ğŸ‰ è¿½åŠ å®Œäº†: {success_count}/{len(data_list)}ä»¶")
        return success_count > 0
    
    def add_single_data(self, data: Dict) -> bool:
        """å˜ä½“ãƒ‡ãƒ¼ã‚¿è¿½åŠ """
        try:
            # ãƒ˜ãƒƒãƒ€ãƒ¼ç¢ºèª
            self.ensure_headers()
            
            # æ¬¡ã®IDã‚’å–å¾—
            next_id = self.get_next_id()
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’è¡Œå½¢å¼ã«å¤‰æ›
            row = self.convert_to_row(data, next_id)
            
            # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«è¿½åŠ 
            self.sheet.append_row(row)
            
            school_name = data.get('school_name', 'Unknown')
            logger.info(f"âœ… è¿½åŠ å®Œäº†: {school_name} (ID: {next_id})")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def get_current_count(self) -> int:
        """ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°"""
        try:
            all_values = self.sheet.get_all_values()
            count = max(0, len(all_values) - 1)  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é™¤ã
            logger.info(f"ğŸ“Š ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {count}æ ¡")
            return count
        except Exception as e:
            logger.error(f"âŒ ä»¶æ•°å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    parser = argparse.ArgumentParser(description='ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆç°¡æ˜“è¿½åŠ ãƒ„ãƒ¼ãƒ«')
    parser.add_argument('--file', required=True, help='è¿½åŠ ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« (JSON/CSV)')
    parser.add_argument('--format', choices=['json', 'csv'], default='json', help='ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼')
    parser.add_argument('--batch-size', type=int, default=10, help='ãƒãƒƒãƒã‚µã‚¤ã‚º')
    parser.add_argument('--credentials', default='credentials.json', help='èªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«')
    
    args = parser.parse_args()
    
    print("ğŸ“Š ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆç°¡æ˜“è¿½åŠ ãƒ„ãƒ¼ãƒ«")
    print("=" * 50)
    
    try:
        # ãƒ„ãƒ¼ãƒ«åˆæœŸåŒ–
        adder = QuickSheetsAdder(args.credentials)
        
        # ç¾åœ¨ã®ä»¶æ•°ç¢ºèª
        current_count = adder.get_current_count()
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        if args.format == 'json':
            data_list = adder.load_json_data(args.file)
        else:
            data_list = adder.load_csv_data(args.file)
        
        if not data_list:
            print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")
            return 1
        
        print(f"ğŸ“ èª­ã¿è¾¼ã¿ãƒ‡ãƒ¼ã‚¿: {len(data_list)}ä»¶")
        
        # ãƒ‡ãƒ¼ã‚¿è¿½åŠ å®Ÿè¡Œ
        success = adder.add_data_batch(data_list, args.batch_size)
        
        if success:
            # æœ€çµ‚ä»¶æ•°ç¢ºèª
            final_count = adder.get_current_count()
            added_count = final_count - current_count
            
            print(f"\nğŸ‰ è¿½åŠ å®Œäº†!")
            print(f"ğŸ“Š è¿½åŠ å‰: {current_count}æ ¡")
            print(f"ğŸ“Š è¿½åŠ å¾Œ: {final_count}æ ¡")
            print(f"ğŸ“ˆ è¿½åŠ æ•°: {added_count}æ ¡")
            print(f"ğŸ”— ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ: https://docs.google.com/spreadsheets/d/{adder.SPREADSHEET_ID}")
            return 0
        else:
            print("âŒ ãƒ‡ãƒ¼ã‚¿è¿½åŠ ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return 1
            
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return 1

if __name__ == "__main__":
    exit(main())
