#!/usr/bin/env python3
"""
é–¢è¥¿120æ ¡ãƒ‡ãƒ¼ã‚¿åé›†å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ - Week 2å®Ÿè¡Œ
Issue #11ã€ŒPhase 3æœ¬æ ¼å®Ÿè¡Œé–‹å§‹ï¼å…¨å›½1000æ ¡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ã€

ç›®çš„:
- é–¢è¥¿6åºœçœŒã‹ã‚‰120æ ¡ã®ãƒ‡ãƒ¼ã‚¿åé›†
- ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆå®Ÿè¡Œã®æˆåŠŸã‚’å—ã‘ãŸæœ¬æ ¼ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹
- å“è³ªA+Bç´š90%ä»¥ä¸Šã®é”æˆï¼ˆãƒ‘ã‚¤ãƒ­ãƒƒãƒˆã‚ˆã‚Šé«˜ã„ç›®æ¨™ï¼‰
- Week 2ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆ8æœˆ9æ—¥ã€œ8æœˆ15æ—¥ï¼‰ã§ã®å®Œäº†

å®Ÿè¡Œè¨ˆç”»:
1. é–¢è¥¿6åºœçœŒã‹ã‚‰è¨ˆ120æ ¡åé›†
2. åºœçœŒåˆ¥é…åˆ†ã«åŸºã¥ãåŠ¹ç‡çš„åé›†
3. ä¸¦è¡Œå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã§ã®é«˜é€ŸåŒ–
4. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—ç›£è¦–

Requirements:
- config.jsonï¼ˆGoogle APIã‚­ãƒ¼è¨­å®šæ¸ˆã¿ï¼‰
- Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDè¨­å®š
- requirements.txtå†…ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
"""

import os
import json
import sys
import time
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import argparse
import concurrent.futures
from threading import Lock

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ„ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from data_collector import DataCollector, SchoolData
from quality_manager import DataQualityManager
from sheets_manager import GoogleSheetsManager
from progress_dashboard import ProgressDashboard

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'kansai_execution_{datetime.now().strftime("%Y%m%d")}.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class KansaiDataCollection:
    """é–¢è¥¿120æ ¡ãƒ‡ãƒ¼ã‚¿åé›†ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config_file: str = "config.json"):
        self.config_file = config_file
        self.load_config()
        
        # ãƒ„ãƒ¼ãƒ«åˆæœŸåŒ–
        self.data_collector = DataCollector(self.config)
        self.quality_manager = DataQualityManager()
        self.sheets_manager = GoogleSheetsManager()
        self.dashboard = ProgressDashboard()
        
        # é–¢è¥¿åé›†è¨­å®šï¼ˆIssue #11æº–æ‹ ï¼‰
        self.target_prefectures = {
            "å¤§é˜ªåºœ": 35,    # å¤§é˜ªå¸‚ãƒ»å ºå¸‚ãƒ»æ±å¤§é˜ªå¸‚ä¸­å¿ƒ
            "å…µåº«çœŒ": 30,    # ç¥æˆ¸å¸‚ãƒ»è¥¿å®®å¸‚ãƒ»å§«è·¯å¸‚ä¸­å¿ƒ
            "äº¬éƒ½åºœ": 25,    # äº¬éƒ½å¸‚ãƒ»å®‡æ²»å¸‚ä¸­å¿ƒ
            "å¥ˆè‰¯çœŒ": 15,    # å¥ˆè‰¯å¸‚ãƒ»æ©¿åŸå¸‚ä¸­å¿ƒ
            "æ»‹è³€çœŒ": 10,    # å¤§æ´¥å¸‚ãƒ»è‰æ´¥å¸‚ä¸­å¿ƒ
            "å’Œæ­Œå±±çœŒ": 5    # å’Œæ­Œå±±å¸‚ä¸­å¿ƒ
        }
        
        self.total_target = sum(self.target_prefectures.values())  # 120æ ¡
        self.start_time = datetime.now()
        
        # å®Ÿè¡Œçµ±è¨ˆï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ï¼‰
        self.stats_lock = Lock()
        self.stats = {
            "attempted": 0,
            "successful": 0,
            "failed": 0,
            "quality_a": 0,
            "quality_b": 0,
            "quality_c": 0,
            "quality_d": 0,
            "api_calls": 0,
            "processing_time": 0,
            "prefecture_progress": {pref: 0 for pref in self.target_prefectures.keys()}
        }
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›®æ¨™ï¼ˆãƒ‘ã‚¤ãƒ­ãƒƒãƒˆå®Ÿè¡Œçµæœã‚’åŸºã«è¨­å®šï¼‰
        self.performance_targets = {
            "quality_ab_rate": 90.0,      # ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆ93.5%ã‚ˆã‚Š90%ç›®æ¨™
            "success_rate": 80.0,         # ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆçµæœã‚ˆã‚Šå‘ä¸Š
            "max_execution_hours": 6.0,   # é€±å†…å®Œäº†ç›®æ¨™
            "avg_time_per_school": 3.0     # 1æ ¡ã‚ãŸã‚Š3ç§’ç›®æ¨™
        }
        
    def load_config(self):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                self.config = json.load(f)
            logger.info(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« {self.config_file} ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        except FileNotFoundError:
            logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« {self.config_file} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            logger.info("config.json.sample ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦è¨­å®šã—ã¦ãã ã•ã„")
            sys.exit(1)
        except json.JSONDecodeError as e:
            logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ãŒä¸æ­£ã§ã™: {e}")
            sys.exit(1)
    
    def validate_environment(self) -> bool:
        """å®Ÿè¡Œç’°å¢ƒãƒã‚§ãƒƒã‚¯ï¼ˆãƒ‘ã‚¤ãƒ­ãƒƒãƒˆå®Ÿè¡Œçµæœã‚’æ´»ç”¨ï¼‰"""
        logger.info("ğŸ” é–¢è¥¿åé›†ç”¨ç’°å¢ƒã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
        
        # åŸºæœ¬è¨­å®šãƒã‚§ãƒƒã‚¯
        required_keys = [
            "google_custom_search_api_key",
            "google_custom_search_engine_id", 
            "google_geocoding_api_key",
            "google_sheets_credentials_file",
            "google_sheets_id"
        ]
        
        missing_keys = [key for key in required_keys if not self.config.get(key)]
        
        if missing_keys:
            logger.error(f"è¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_keys}")
            return False
        
        # Google Sheetsæ¥ç¶šãƒ†ã‚¹ãƒˆ
        try:
            sheet_info = self.sheets_manager.get_sheet_info()
            current_rows = sheet_info.get("total_rows", 0)
            logger.info(f"âœ… Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ¥ç¶šOKï¼ˆç¾åœ¨ {current_rows} è¡Œï¼‰")
        except Exception as e:
            logger.error(f"âŒ Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ¥ç¶šå¤±æ•—: {e}")
            return False
        
        # APIåˆ¶é™ãƒã‚§ãƒƒã‚¯ï¼ˆé–¢è¥¿åé›†ç”¨ï¼‰
        api_quotas = self.config.get("api_quotas", {})
        daily_limit = api_quotas.get("search_daily_limit", 100)
        estimated_api_calls = self.total_target * 3  # 1æ ¡ã‚ãŸã‚Š3å›ã®APIå‘¼ã³å‡ºã—
        
        if daily_limit < estimated_api_calls:
            logger.warning(f"âš ï¸ æ—¥æ¬¡APIåˆ¶é™ ({daily_limit}) ãŒæ¨å®šå¿…è¦æ•° ({estimated_api_calls}) ã‚’ä¸‹å›ã‚Šã¾ã™")
        
        # ä¸¦è¡Œå‡¦ç†è¨­å®šãƒã‚§ãƒƒã‚¯
        max_workers = self.config.get("max_workers", 3)
        if max_workers > 5:
            logger.warning("âš ï¸ ä¸¦è¡Œå‡¦ç†æ•°ãŒå¤šã™ãã¾ã™ã€‚APIåˆ¶é™ã«æ³¨æ„ã—ã¦ãã ã•ã„")
        
        logger.info("âœ… é–¢è¥¿åé›†ç’°å¢ƒãƒã‚§ãƒƒã‚¯å®Œäº†")
        return True
    
    def execute_prefecture_collection_parallel(self, prefecture: str, target_count: int) -> List[SchoolData]:
        """éƒ½é“åºœçœŒåˆ¥ãƒ‡ãƒ¼ã‚¿åé›†ï¼ˆä¸¦è¡Œå‡¦ç†å¯¾å¿œï¼‰"""
        logger.info(f"ğŸ“ {prefecture} ã®ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹ï¼ˆç›®æ¨™: {target_count}æ ¡ï¼‰")
        
        collected_schools = []
        prefecture_start = time.time()
        
        try:
            # ä¸­å­¦æ ¡ãƒ‡ãƒ¼ã‚¿åé›†ï¼ˆä¸¦è¡Œå‡¦ç†ï¼‰
            schools = self.data_collector.collect_schools_by_prefecture_parallel(
                prefecture=prefecture,
                school_type="ä¸­å­¦æ ¡",
                max_schools=target_count,
                max_workers=self.config.get("max_workers", 3),
                include_quality_check=True
            )
            
            logger.info(f"ğŸ« {prefecture}: {len(schools)}æ ¡ã‚’åé›†")
            
            # å“è³ªè©•ä¾¡ã¨ãƒãƒ¼ã‚­ãƒ³ã‚°
            for school in schools:
                with self.stats_lock:
                    self.stats["attempted"] += 1
                
                # å“è³ªãƒã‚§ãƒƒã‚¯
                quality_level, quality_score, issues = self.quality_manager.evaluate_school_quality(school)
                school.quality_level = quality_level
                school.quality_score = quality_score
                school.quality_issues = issues
                school.collection_batch = "kansai_week2"
                school.prefecture_collection_order = len(collected_schools) + 1
                
                # çµ±è¨ˆæ›´æ–°ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ï¼‰
                with self.stats_lock:
                    if hasattr(school, 'full_lyrics') and school.full_lyrics:
                        self.stats["successful"] += 1
                        self.stats[f"quality_{quality_level.lower()}"] += 1
                        self.stats["prefecture_progress"][prefecture] += 1
                        collected_schools.append(school)
                    else:
                        self.stats["failed"] += 1
                        logger.warning(f"âŒ ãƒ‡ãƒ¼ã‚¿ä¸è¶³: {school.school_name}")
            
            prefecture_time = time.time() - prefecture_start
            achievement_rate = (len(collected_schools) / target_count) * 100
            
            logger.info(f"âœ… {prefecture} å®Œäº† ({prefecture_time:.1f}ç§’, é”æˆç‡: {achievement_rate:.1f}%)")
            
        except Exception as e:
            logger.error(f"âŒ {prefecture} ã§ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ã‚ã‚‹ç¨‹åº¦ã®ãƒ‡ãƒ¼ã‚¿ã¯è¿”ã™
        
        return collected_schools
    
    def update_progress_dashboard(self, current_schools: List[SchoolData]):
        """é€²æ—ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ›´æ–°"""
        try:
            progress_data = {
                "collection_phase": "Week2_Kansai",
                "target_total": self.total_target,
                "collected_total": len(current_schools),
                "achievement_rate": (len(current_schools) / self.total_target) * 100,
                "prefecture_progress": dict(self.stats["prefecture_progress"]),
                "quality_distribution": {
                    "A": self.stats["quality_a"],
                    "B": self.stats["quality_b"],
                    "C": self.stats["quality_c"],
                    "D": self.stats["quality_d"]
                },
                "performance_metrics": {
                    "quality_ab_rate": ((self.stats["quality_a"] + self.stats["quality_b"]) / len(current_schools)) * 100 if current_schools else 0,
                    "success_rate": (self.stats["successful"] / self.stats["attempted"]) * 100 if self.stats["attempted"] > 0 else 0,
                    "avg_time_per_school": (datetime.now() - self.start_time).total_seconds() / len(current_schools) if current_schools else 0
                },
                "updated_at": datetime.now().isoformat()
            }
            
            # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ›´æ–°
            self.dashboard.update_progress(progress_data)
            
        except Exception as e:
            logger.warning(f"âš ï¸ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
    
    def save_kansai_checkpoint(self, schools: List[SchoolData], checkpoint_name: str):
        """é–¢è¥¿åé›†å°‚ç”¨ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"kansai_week2_checkpoint_{checkpoint_name}_{timestamp}.json"
        
        # é–¢è¥¿åé›†ç”¨æ‹¡å¼µãƒ‡ãƒ¼ã‚¿
        schools_data = []
        for school in schools:
            school_dict = {
                "school_name": school.school_name,
                "prefecture": school.prefecture,
                "city": school.city,
                "address": school.address,
                "latitude": school.latitude,
                "longitude": school.longitude,
                "full_lyrics": school.full_lyrics,
                "masked_lyrics": school.masked_lyrics,
                "difficulty": school.difficulty,
                "hints": school.hints,
                "data_source": school.data_source,
                "collection_date": school.collection_date,
                "quality_level": getattr(school, 'quality_level', 'PENDING'),
                "quality_score": getattr(school, 'quality_score', 0),
                "quality_issues": getattr(school, 'quality_issues', []),
                "collection_batch": getattr(school, 'collection_batch', 'kansai_week2'),
                "prefecture_collection_order": getattr(school, 'prefecture_collection_order', 0)
            }
            schools_data.append(school_dict)
        
        checkpoint_data = {
            "collection_phase": "Week2_Kansai",
            "checkpoint": checkpoint_name,
            "timestamp": timestamp,
            "total_schools": len(schools),
            "stats": dict(self.stats),
            "prefecture_targets": self.target_prefectures,
            "performance_targets": self.performance_targets,
            "schools": schools_data,
            "execution_metadata": {
                "start_time": self.start_time.isoformat(),
                "current_time": datetime.now().isoformat(),
                "elapsed_hours": (datetime.now() - self.start_time).total_seconds() / 3600
            }
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(checkpoint_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ é–¢è¥¿åé›†ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ {filename} ã«ä¿å­˜")
        return filename
    
    def upload_kansai_data_to_sheets(self, schools: List[SchoolData]) -> bool:
        """é–¢è¥¿ãƒ‡ãƒ¼ã‚¿ã®Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
        try:
            logger.info("â˜ï¸ é–¢è¥¿ãƒ‡ãƒ¼ã‚¿ã‚’Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
            
            # é–¢è¥¿å°‚ç”¨ã‚·ãƒ¼ãƒˆã¾ãŸã¯æ—¢å­˜ã‚·ãƒ¼ãƒˆã«è¿½è¨˜
            sheet_name = "Kansai_Week2"
            
            # ãƒãƒƒãƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆ50æ ¡ãšã¤ã€APIåˆ¶é™è€ƒæ…®ï¼‰
            batch_size = 50
            total_uploaded = 0
            
            for i in range(0, len(schools), batch_size):
                batch = schools[i:i + batch_size]
                
                # é–¢è¥¿åé›†ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                for school in batch:
                    school.week_number = 2
                    school.region = "é–¢è¥¿"
                    school.cumulative_total_schools = total_uploaded + len(batch)
                
                self.sheets_manager.add_schools_batch(batch, sheet_name=sheet_name)
                total_uploaded += len(batch)
                
                logger.info(f"ğŸ“¤ {total_uploaded}/{len(schools)}æ ¡ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†")
                
                # APIåˆ¶é™å¯¾ç­–ï¼ˆé–¢è¥¿ãƒ‡ãƒ¼ã‚¿é‡è€ƒæ…®ï¼‰
                time.sleep(3)
            
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†ãƒ­ã‚°
            logger.info(f"âœ… é–¢è¥¿120æ ¡Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†")
            logger.info(f"ğŸ“Š ç´¯è¨ˆãƒ‡ãƒ¼ã‚¿: é–¢æ±108æ ¡ + é–¢è¥¿{len(schools)}æ ¡ = {108 + len(schools)}æ ¡")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ é–¢è¥¿ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def generate_kansai_week2_report(self, all_schools: List[SchoolData]) -> Dict:
        """é–¢è¥¿Week2å®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        execution_time = datetime.now() - self.start_time
        
        # åºœçœŒåˆ¥è©³ç´°åˆ†æ
        prefecture_analysis = {}
        for school in all_schools:
            pref = school.prefecture
            if pref not in prefecture_analysis:
                prefecture_analysis[pref] = {
                    "collected": 0,
                    "target": self.target_prefectures.get(pref, 0),
                    "quality_grades": {"A": 0, "B": 0, "C": 0, "D": 0},
                    "average_quality_score": 0,
                    "collection_issues": []
                }
            
            analysis = prefecture_analysis[pref]
            analysis["collected"] += 1
            
            quality_level = getattr(school, 'quality_level', 'D')
            analysis["quality_grades"][quality_level] += 1
            
            # å“è³ªèª²é¡Œã®é›†è¨ˆ
            quality_issues = getattr(school, 'quality_issues', [])
            analysis["collection_issues"].extend(quality_issues)
        
        # åºœçœŒåˆ¥æˆç¸¾è¨ˆç®—
        for pref, analysis in prefecture_analysis.items():
            analysis["achievement_rate"] = (analysis["collected"] / analysis["target"]) * 100 if analysis["target"] > 0 else 0
            analysis["quality_ab_rate"] = ((analysis["quality_grades"]["A"] + analysis["quality_grades"]["B"]) / analysis["collected"]) * 100 if analysis["collected"] > 0 else 0
            analysis["unique_issues"] = list(set(analysis["collection_issues"]))
        
        # å…¨ä½“ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
        total_collected = len(all_schools)
        quality_ab_rate = ((self.stats["quality_a"] + self.stats["quality_b"]) / total_collected) * 100 if total_collected > 0 else 0
        success_rate = (self.stats["successful"] / self.stats["attempted"]) * 100 if self.stats["attempted"] > 0 else 0
        avg_time_per_school = execution_time.total_seconds() / total_collected if total_collected > 0 else 0
        
        # ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆå®Ÿè¡Œã¨ã®æ¯”è¼ƒ
        pilot_comparison = {
            "pilot_quality_ab_rate": 93.5,  # ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆå®Ÿè¡Œçµæœ
            "kansai_quality_ab_rate": quality_ab_rate,
            "quality_improvement": quality_ab_rate - 93.5,
            "pilot_avg_time": 2.0,  # ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆã®æ¨å®šå€¤
            "kansai_avg_time": avg_time_per_school,
            "efficiency_improvement": ((2.0 - avg_time_per_school) / 2.0) * 100 if avg_time_per_school > 0 else 0
        }
        
        # é€±æ¬¡é€²æ—ï¼ˆç´¯è¨ˆï¼‰
        cumulative_progress = {
            "week1_kanto": 108,
            "week2_kansai": total_collected,
            "total_collected": 108 + total_collected,
            "target_1000": 1000,
            "overall_progress_rate": ((108 + total_collected) / 1000) * 100,
            "remaining_schools": 1000 - (108 + total_collected),
            "weeks_remaining": 6,
            "required_weekly_rate": (1000 - (108 + total_collected)) / 6 if 108 + total_collected < 1000 else 0
        }
        
        report = {
            "kansai_week2_summary": {
                "collection_phase": "Week2_Kansai",
                "start_time": self.start_time.isoformat(),
                "end_time": datetime.now().isoformat(),
                "execution_time_hours": execution_time.total_seconds() / 3600,
                "target_schools": self.total_target,
                "collected_schools": total_collected,
                "achievement_rate": (total_collected / self.total_target) * 100,
                "success_rate": success_rate,
                "quality_ab_rate": quality_ab_rate
            },
            "performance_vs_targets": {
                "quality_ab_target": self.performance_targets["quality_ab_rate"],
                "quality_ab_actual": quality_ab_rate,
                "quality_target_met": quality_ab_rate >= self.performance_targets["quality_ab_rate"],
                "success_rate_target": self.performance_targets["success_rate"],
                "success_rate_actual": success_rate,
                "success_target_met": success_rate >= self.performance_targets["success_rate"],
                "time_target_hours": self.performance_targets["max_execution_hours"],
                "time_actual_hours": execution_time.total_seconds() / 3600,
                "time_target_met": execution_time.total_seconds() / 3600 <= self.performance_targets["max_execution_hours"]
            },
            "pilot_comparison": pilot_comparison,
            "prefecture_breakdown": prefecture_analysis,
            "cumulative_progress": cumulative_progress,
            "next_week_planning": {
                "week3_target_region": "ä¸­éƒ¨",
                "week3_target_schools": 100,
                "estimated_completion_date": (datetime.now() + timedelta(weeks=1)).strftime("%Y-%m-%d"),
                "recommended_adjustments": self._generate_week3_recommendations(quality_ab_rate, success_rate, avg_time_per_school)
            },
            "quality_insights": self._analyze_quality_patterns(all_schools),
            "recommendations": self._generate_kansai_recommendations(quality_ab_rate, success_rate, avg_time_per_school)
        }
        
        return report
    
    def _analyze_quality_patterns(self, schools: List[SchoolData]) -> Dict:
        """å“è³ªãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        patterns = {
            "high_quality_prefectures": [],
            "improvement_needed_prefectures": [],
            "common_quality_issues": {},
            "data_source_effectiveness": {}
        }
        
        # åºœçœŒåˆ¥å“è³ªåˆ†æ
        for pref in self.target_prefectures.keys():
            pref_schools = [s for s in schools if s.prefecture == pref]
            if pref_schools:
                quality_ab_count = sum(1 for s in pref_schools if getattr(s, 'quality_level', 'D') in ['A', 'B'])
                quality_ab_rate = (quality_ab_count / len(pref_schools)) * 100
                
                if quality_ab_rate >= 90:
                    patterns["high_quality_prefectures"].append({
                        "prefecture": pref,
                        "quality_ab_rate": quality_ab_rate,
                        "schools_count": len(pref_schools)
                    })
                elif quality_ab_rate < 80:
                    patterns["improvement_needed_prefectures"].append({
                        "prefecture": pref,
                        "quality_ab_rate": quality_ab_rate,
                        "schools_count": len(pref_schools)
                    })
        
        return patterns
    
    def _generate_week3_recommendations(self, quality_rate: float, success_rate: float, avg_time: float) -> List[str]:
        """Week3å‘ã‘æ¨å¥¨äº‹é …"""
        recommendations = []
        
        if quality_rate >= 90:
            recommendations.append("å“è³ªç›®æ¨™é”æˆã€‚ä¸­éƒ¨åé›†ã§ã‚‚åŒã˜æ‰‹æ³•ã‚’ç¶™ç¶š")
        else:
            recommendations.append("å“è³ªå‘ä¸Šã®ãŸã‚ã€ä¸­éƒ¨åé›†ã§ã¯ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é¸å®šã‚’å¼·åŒ–")
        
        if avg_time <= 3.0:
            recommendations.append("åŠ¹ç‡ç›®æ¨™é”æˆã€‚ä¸­éƒ¨åé›†ã§ã¯ä¸¦è¡Œå‡¦ç†æ•°ã‚’å¢—åŠ å¯èƒ½")
        else:
            recommendations.append("å‡¦ç†æ™‚é–“æ”¹å–„ã®ãŸã‚ã€ä¸­éƒ¨åé›†ã§ã¯APIå‘¼ã³å‡ºã—æœ€é©åŒ–ã‚’å®Ÿæ–½")
        
        recommendations.append("é€±æ¬¡é€²æ—è‰¯å¥½ã€‚Week3ã¯æ„›çŸ¥ãƒ»é™å²¡ãƒ»ä¸‰é‡ã‚’é‡ç‚¹çš„ã«åé›†")
        
        return recommendations
    
    def _generate_kansai_recommendations(self, quality_rate: float, success_rate: float, avg_time: float) -> List[str]:
        """é–¢è¥¿åé›†ç·åˆæ¨å¥¨äº‹é …"""
        recommendations = []
        
        if quality_rate >= 85 and success_rate >= 75:
            recommendations.append("âœ… é–¢è¥¿åé›†æˆåŠŸã€‚Week3ä¸­éƒ¨åé›†ã«ç§»è¡Œå¯èƒ½")
            recommendations.append("ğŸš€ ä¸¦è¡Œå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®æœ¬æ ¼ç¨¼åƒç¶™ç¶š")
        elif quality_rate >= 75:
            recommendations.append("âš ï¸ éƒ¨åˆ†çš„æˆåŠŸã€‚å“è³ªç®¡ç†ã‚’å¼·åŒ–ã—ã¦ä¸­éƒ¨åé›†ã«ç§»è¡Œ")
        else:
            recommendations.append("âŒ å“è³ªç›®æ¨™æœªé”ã€‚ãƒ„ãƒ¼ãƒ«èª¿æ•´å¾Œã«ä¸­éƒ¨åé›†é–‹å§‹")
        
        if avg_time <= 4.0:
            recommendations.append("â±ï¸ å‡¦ç†åŠ¹ç‡è‰¯å¥½ã€‚å…¨å›½1000æ ¡åé›†ãƒšãƒ¼ã‚¹ã‚’ç¶­æŒ")
        else:
            recommendations.append("â±ï¸ å‡¦ç†åŠ¹ç‡æ”¹å–„ãŒå¿…è¦ã€‚APIæœ€é©åŒ–ã‚’å®Ÿæ–½")
        
        recommendations.append("ğŸ“Š MVPã‚¢ãƒ—ãƒªã¸ã®ç´¯è¨ˆ228æ ¡ãƒ‡ãƒ¼ã‚¿çµ±åˆã‚’å®Ÿæ–½")
        
        return recommendations
    
    def run_kansai_collection(self, dry_run: bool = False, parallel: bool = True) -> Dict:
        """é–¢è¥¿120æ ¡åé›†ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
        logger.info("ğŸš€ é–¢è¥¿120æ ¡ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹ - Week 2å®Ÿè¡Œ")
        logger.info("=" * 60)
        logger.info(f"ğŸ“… å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}")
        logger.info(f"ğŸ¯ ç›®æ¨™: é–¢è¥¿6åºœçœŒã‹ã‚‰120æ ¡åé›†")
        logger.info(f"ğŸ“Š å“è³ªç›®æ¨™: A+Bç´š90%ä»¥ä¸Š")
        logger.info("=" * 60)
        
        # ç’°å¢ƒãƒã‚§ãƒƒã‚¯
        if not self.validate_environment():
            logger.error("âŒ ç’°å¢ƒãƒã‚§ãƒƒã‚¯ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return {"success": False, "error": "Environment validation failed"}
        
        if dry_run:
            logger.info("ğŸ§ª DRY RUN ãƒ¢ãƒ¼ãƒ‰: å®Ÿéš›ã®åé›†ã¯è¡Œã„ã¾ã›ã‚“")
        
        all_schools = []
        
        # ä¸¦è¡Œå‡¦ç† vs é †æ¬¡å‡¦ç†
        if parallel and not dry_run:
            logger.info("ğŸ”„ ä¸¦è¡Œå‡¦ç†ãƒ¢ãƒ¼ãƒ‰ã§é–¢è¥¿åé›†ã‚’å®Ÿè¡Œ")
            
            # åºœçœŒåˆ¥ä¸¦è¡Œå‡¦ç†å®Ÿè¡Œ
            with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
                future_to_prefecture = {
                    executor.submit(self.execute_prefecture_collection_parallel, pref, target): pref
                    for pref, target in self.target_prefectures.items()
                }
                
                for future in concurrent.futures.as_completed(future_to_prefecture):
                    prefecture = future_to_prefecture[future]
                    try:
                        schools = future.result()
                        all_schools.extend(schools)
                        logger.info(f"âœ… {prefecture} ä¸¦è¡Œå‡¦ç†å®Œäº†: {len(schools)}æ ¡")
                        
                        # é€²æ—ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ›´æ–°
                        self.update_progress_dashboard(all_schools)
                        
                    except Exception as e:
                        logger.error(f"âŒ {prefecture} ä¸¦è¡Œå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        
        else:
            # é †æ¬¡å‡¦ç†ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ãƒ»DRY RUNç”¨ï¼‰
            for i, (prefecture, target_count) in enumerate(self.target_prefectures.items(), 1):
                logger.info(f"ğŸ“ ({i}/{len(self.target_prefectures)}) {prefecture} é–‹å§‹")
                
                if not dry_run:
                    schools = self.execute_prefecture_collection_parallel(prefecture, target_count)
                    all_schools.extend(schools)
                    
                    # é€²æ—ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ›´æ–°
                    self.update_progress_dashboard(all_schools)
                    
                    # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ï¼ˆ2åºœçœŒæ¯ï¼‰
                    if i % 2 == 0:
                        self.save_kansai_checkpoint(all_schools, f"prefecture_{i}")
                    
                    # APIåˆ¶é™å¯¾ç­–
                    time.sleep(5)
                else:
                    logger.info(f"ğŸ§ª DRY RUN: {prefecture} ã® {target_count}æ ¡ã‚’åé›†äºˆå®š")
        
        logger.info("=" * 60)
        logger.info(f"âœ… é–¢è¥¿ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†: {len(all_schools)}æ ¡")
        
        # æœ€çµ‚çµæœå‡¦ç†
        if not dry_run and all_schools:
            # æœ€çµ‚ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
            final_checkpoint = self.save_kansai_checkpoint(all_schools, "final")
            
            # Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            upload_success = self.upload_kansai_data_to_sheets(all_schools)
            
            # é–¢è¥¿Week2ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            report = self.generate_kansai_week2_report(all_schools)
        else:
            # DRY RUN ãƒ¬ãƒãƒ¼ãƒˆ
            report = {
                "kansai_week2_summary": {
                    "mode": "DRY_RUN",
                    "target_schools": self.total_target,
                    "prefecture_plan": self.target_prefectures,
                    "estimated_execution_hours": 4.0
                }
            }
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"kansai_week2_report_{timestamp}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“‹ é–¢è¥¿Week2ãƒ¬ãƒãƒ¼ãƒˆ: {report_file}")
        
        return {
            "success": True,
            "collected_schools": len(all_schools) if not dry_run else 0,
            "report_file": report_file,
            "report": report,
            "cumulative_total": 108 + len(all_schools) if not dry_run else 108  # é–¢æ±108æ ¡ + é–¢è¥¿çµæœ
        }

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(description="é–¢è¥¿120æ ¡ãƒ‡ãƒ¼ã‚¿åé›†å®Ÿè¡Œ")
    parser.add_argument("--dry-run", action="store_true", help="å®Ÿéš›ã®åé›†ã¯è¡Œã‚ãšè¨ˆç”»ã®ã¿è¡¨ç¤º")
    parser.add_argument("--config", default="config.json", help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
    parser.add_argument("--sequential", action="store_true", help="ä¸¦è¡Œå‡¦ç†ã§ã¯ãªãé †æ¬¡å‡¦ç†ã§å®Ÿè¡Œ")
    
    args = parser.parse_args()
    
    print("ğŸ« é–¢è¥¿120æ ¡ãƒ‡ãƒ¼ã‚¿åé›† - Week 2å®Ÿè¡Œ")
    print("=" * 50)
    print("ğŸ“‹ å®Ÿè¡Œè¨ˆç”»:")
    print("- å¯¾è±¡: é–¢è¥¿6åºœçœŒï¼ˆå¤§é˜ªãƒ»å…µåº«ãƒ»äº¬éƒ½ãƒ»å¥ˆè‰¯ãƒ»æ»‹è³€ãƒ»å’Œæ­Œå±±ï¼‰")
    print("- ç›®æ¨™: 120æ ¡")
    print("- å“è³ªç›®æ¨™: A+Bç´š90%ä»¥ä¸Š")
    print("- ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«: Week 2ï¼ˆ8æœˆ9æ—¥ã€œ8æœˆ15æ—¥ï¼‰")
    print("- ç´¯è¨ˆç›®æ¨™: é–¢æ±108æ ¡ + é–¢è¥¿120æ ¡ = 228æ ¡")
    
    if args.dry_run:
        print("ğŸ§ª DRY RUN ãƒ¢ãƒ¼ãƒ‰")
    
    if args.sequential:
        print("ğŸ“ é †æ¬¡å‡¦ç†ãƒ¢ãƒ¼ãƒ‰")
    else:
        print("âš¡ ä¸¦è¡Œå‡¦ç†ãƒ¢ãƒ¼ãƒ‰")
    
    print("=" * 50)
    
    # å®Ÿè¡Œç¢ºèª
    if not args.dry_run:
        response = input("é–¢è¥¿120æ ¡ãƒ‡ãƒ¼ã‚¿åé›†ã‚’é–‹å§‹ã—ã¾ã™ã‹ï¼Ÿ (y/N): ")
        if response.lower() != 'y':
            print("âŒ å®Ÿè¡ŒãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
            return
    
    # é–¢è¥¿åé›†å®Ÿè¡Œ
    kansai_collection = KansaiDataCollection(args.config)
    result = kansai_collection.run_kansai_collection(
        dry_run=args.dry_run,
        parallel=not args.sequential
    )
    
    # çµæœè¡¨ç¤º
    if result["success"]:
        print("\n" + "=" * 50)
        print("ğŸ‰ é–¢è¥¿Week2åé›†å®Œäº†")
        print("=" * 50)
        
        if not args.dry_run:
            report = result["report"]
            summary = report["kansai_week2_summary"]
            
            print(f"åé›†å­¦æ ¡æ•°: {summary['collected_schools']}/{summary['target_schools']}æ ¡")
            print(f"é”æˆç‡: {summary['achievement_rate']:.1f}%")
            print(f"æˆåŠŸç‡: {summary['success_rate']:.1f}%")
            print(f"å“è³ªA+Bç´šç‡: {summary['quality_ab_rate']:.1f}%")
            print(f"å®Ÿè¡Œæ™‚é–“: {summary['execution_time_hours']:.1f}æ™‚é–“")
            print(f"ç´¯è¨ˆãƒ‡ãƒ¼ã‚¿: {result['cumulative_total']}æ ¡ï¼ˆå…¨å›½1000æ ¡ã®{result['cumulative_total']/10:.1f}%ï¼‰")
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›®æ¨™é”æˆçŠ¶æ³
            targets_met = report["performance_vs_targets"]
            print(f"\nğŸ¯ ç›®æ¨™é”æˆçŠ¶æ³:")
            print(f"- å“è³ªç›®æ¨™: {'âœ…' if targets_met['quality_target_met'] else 'âŒ'}")
            print(f"- æˆåŠŸç‡ç›®æ¨™: {'âœ…' if targets_met['success_target_met'] else 'âŒ'}")
            print(f"- æ™‚é–“ç›®æ¨™: {'âœ…' if targets_met['time_target_met'] else 'âŒ'}")
            
            print(f"\nğŸ“‹ æ¨å¥¨äº‹é …:")
            for rec in report["recommendations"]:
                print(f"- {rec}")
            
            print(f"\nğŸ¯ Week3è¨ˆç”»:")
            week3 = report["next_week_planning"]
            print(f"- å¯¾è±¡åœ°åŸŸ: {week3['target_region']}")
            print(f"- ç›®æ¨™æ ¡æ•°: {week3['target_schools']}æ ¡")
            print(f"- äºˆå®šå®Œäº†: {week3['estimated_completion_date']}")
        
        print(f"\nğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: {result['report_file']}")
        
    else:
        print("âŒ é–¢è¥¿åé›†ã«å¤±æ•—ã—ã¾ã—ãŸ")
        if "error" in result:
            print(f"ã‚¨ãƒ©ãƒ¼: {result['error']}")

if __name__ == "__main__":
    main()
